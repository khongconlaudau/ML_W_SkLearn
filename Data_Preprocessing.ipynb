{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6956fe91-3471-49b9-8789-dff379c232a6",
   "metadata": {},
   "source": [
    "# Using ColumnTransformer in Scikit-Learn for Data Preprocessing\n",
    "- Data preprocessing is a critical step in any machine learning workflow. It involves cleaning and transforming raw data into a format suitable for modeling. One of the challenges in preprocessing is dealing with datasets that contain different types of features, such as numerical and categorical data. Scikit-learn's ColumnTransformer is a powerful tool that allows you to apply different transformations to different subsets of features within your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb74f3b-5c70-434b-a02e-9d0b4b5b3c83",
   "metadata": {},
   "source": [
    "## Preprocessing Strategies with ColumnTransformer\n",
    "- Here Let's create a dataset which is named as CAR_SPEED_DATA which consists of 6 columns named as:\n",
    "\n",
    "    - AGE: This column contains numerical data representing the age of individuals. It's a continuous variable that may require scaling to ensure it fits well within our model.\n",
    "    - GENDER: A categorical feature that denotes the gender of individuals, often represented as 'Male' or 'Female.' To make this data usable for machine learning models, we'll need to encode it into numerical values.\n",
    "    - SPEED: Another numerical feature, this column represents the speed of an individual’s vehicle. Like AGE, it might need scaling or normalization.\n",
    "    - AVERAGE_SPEED: This feature is an ordinal categorical value. It represents speed categories like 'high' or 'low' .Although it seems similar to numerical data, it needs special handling because the order matters but the differences between categories are not consistent.\n",
    "    - CITY: A categorical feature indicating the city where the individual resides. With potentially many unique values, we'll need to apply one-hot encoding to convert it into a form suitable for modeling.\n",
    "    - HAS_DRIVING_LICENSE: This binary categorical variable shows whether an individual has a driving license ('Yes' or 'No'). Simple encoding can transform this into a numerical feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ca8ed-6d47-413c-8d67-867028e88310",
   "metadata": {},
   "source": [
    "## Challenges Without Column Transformer\n",
    "- When we work with such a diverse dataset, different preprocessing steps are required for different columns:\n",
    "\n",
    "- Numerical Data Handling:\n",
    "\n",
    "    - AGE and SPEED need to be scaled to ensure that they don’t overpower other features in the model. Without proper scaling, numerical columns with larger ranges could disproportionately affect the model's learning process.\n",
    "    - Categorical Encoding: GENDER and CITY need encoding into numerical formats. With multiple categorical features, applying encoding manually can be big task, especially when dealing with a large number of categories.\n",
    "    - Ordinal Encoding: AVERAGE_SPEED, as an ordinal categorical feature, requires careful encoding to preserve the order of categories. Applying standard one-hot encoding might not respect this inherent ordering.\n",
    "    - Binary Features: The HAS_DRIVING_LICENSE column is binary and relatively straightforward, but it's another step that adds complexity when handled separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a07029-e0ba-4793-8a4c-887329a53b0a",
   "metadata": {},
   "source": [
    "## Implementing Column Transformer in Sklearn\n",
    "- SimpleImputer: Used to fill in missing data in a dataset with a specified strategy, such as mean, median, or mode, we use mean in our dataset.\n",
    "- OneHotEncoder: Converts categorical features into a format that can be provided to machine learning algorithms by creating binary columns for each category.\n",
    "- OrdinalEncoder: Transforms categorical features into integer values that represent the ordinal relationship between categories, preserving their order. In our dataset for low speed we encode it as '0' for high speed we encode it '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea3da45-0163-497d-93b9-067769421116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np \n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07045c0-2227-477c-835b-2acfaa92fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Average_speed</th>\n",
       "      <th>City</th>\n",
       "      <th>has_driving_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>low</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>female</td>\n",
       "      <td>70.0</td>\n",
       "      <td>low</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>140.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>120.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>low</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Speed Average_speed     City has_driving_license\n",
       "0   54    male   40.0           low  Kolkata                 yes\n",
       "1   34  female   70.0           low    Delhi                 yes\n",
       "2   19  female  140.0          high    Delhi                  no\n",
       "3   45    male  120.0          high  Kolkata                 yes\n",
       "4   23    male   80.0           low   Mumbai                  no"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Car_Speed_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92697b7-c1cd-4f9c-a34d-45d67581da4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                    0\n",
       "Gender                 0\n",
       "Speed                  9\n",
       "Average_speed          0\n",
       "City                   0\n",
       "has_driving_license    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d82e93-e703-44ed-9583-53cb834a62b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Age  Gender  Speed Average_speed      City\n",
       " 82   51  female  170.0          high    Mumbai\n",
       " 14   37  female   70.0           low  Banglore\n",
       " 77   36    male  130.0          high  Banglore\n",
       " 25   35    male  100.0          high  Banglore\n",
       " 33   35  female   50.0           low  Banglore\n",
       " ..  ...     ...    ...           ...       ...\n",
       " 45   24  female   60.0           low   Kolkata\n",
       " 46   19  female   70.0           low  Banglore\n",
       " 26   47  female  130.0          high  Banglore\n",
       " 28   27  female  150.0          high     Delhi\n",
       " 84   46  female   50.0           low     Delhi\n",
       " \n",
       " [80 rows x 5 columns],\n",
       " (80, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['has_driving_license']), \n",
    "                                                   df['has_driving_license'], \n",
    "                                                   test_size=0.2)\n",
    "X_train, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ba834b-e460-4c9b-9955-e652fc07d4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are using SimpleImputer() for speed Column\n",
    "si = SimpleImputer()\n",
    "X_train_Speed = si.fit_transform(X_train[['Speed']])\n",
    "\n",
    "#for test data\n",
    "X_test_Speed = si.fit_transform(X_test[['Speed']])\n",
    "\n",
    "X_train_Speed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e268f90-86f0-4f8c-adbc-3c61039d9678",
   "metadata": {},
   "source": [
    "- The Average_speed column is an ordinal categorical feature, meaning its categories have a meaningful order, such as low and high. By using OrdinalEncoder, we transform these categories into numerical values that preserve their inherent order. This encoding allows machine learning models to interpret the relative significance of each category, enabling them to capture patterns associated with different speeds. For instance, if low is encoded as 0 and high as 1, the model can recognize that high represents a greater speed than low, impacting how it learns relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1099c84e-f100-4167-8cd7-75a7b6237854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinalencoding for Average_speed\n",
    "eo = OrdinalEncoder(categories=[['low', 'high']])\n",
    "X_train_Average_speed  = eo.fit_transform(X_train[[\"Average_speed\"]])\n",
    "\n",
    "# for test data\n",
    "X_test_Average_speed = eo.fit_transform(X_test[['Average_speed']])\n",
    "\n",
    "X_train_Average_speed.shape\n",
    "X_train_Average_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f923076-0a31-42dd-ab62-74fb3ac5c35c",
   "metadata": {},
   "source": [
    "- One-Hot Encoding is used to convert categorical variables into a binary matrix, allowing machine learning models to interpret these features without assuming any ordinal relationship. By transforming Gender and City into binary columns, we avoid misleading the model into thinking there's a rank or order between the categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b0576a-8ed4-4805-b1ed-d9d01f29ef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 5),\n",
       " array([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing OneHotEncoding for Gender,City\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_train_Gender_City = ohe.fit_transform(X_train[['Gender', 'City']])\n",
    "\n",
    "# For the dataset \n",
    "X_test_Gender_City = ohe.fit_transform(X_test[['Gender', 'City']])\n",
    "X_train_Gender_City.shape, X_train_Gender_City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68029ffd-278a-4af3-b136-65ebf2521da3",
   "metadata": {},
   "source": [
    "- The Age feature is a numerical variable that often plays a critical role in predictive modeling .By extracting Age separately, we can focus on its unique contribution to the model without interference from categorical features This separation also simplifies preprocessing steps, such as scaling or normalizing numerical data, ensuring that age is treated with its own distinct statistical(mean,median,mode) considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "583fdc5d-27a0-41c3-a75a-130a7d8a08c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Age\n",
    "X_train_age = X_train.drop(columns=['Gender','Speed','Average_speed','City']).values\n",
    "\n",
    "X_test_age = X_test.drop(columns=['Gender','Speed','Average_speed','City']).values\n",
    "\n",
    "X_train_age.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15bd584-0805-4140-a378-fac3412daf0f",
   "metadata": {},
   "source": [
    "### Without using Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "505f307e-47f1-48aa-aef0-c2ee8cabac06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = np.concatenate((X_train_age,X_train_Speed,X_train_Gender_City,X_train_Average_speed),axis=1)\n",
    "\n",
    "X_test_transformed = np.concatenate((X_test_age,X_test_Speed,X_test_Gender_City,X_test_Average_speed),axis=1)\n",
    "\n",
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbac51-228f-4b20-be59-435976ce53cd",
   "metadata": {},
   "source": [
    "## Using Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b317d382-4133-4e51-9b9e-ae22865caec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f336458-5707-4423-8514-43bb9b17f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('t1', SimpleImputer(), ['Speed']),\n",
    "    ('t2', OrdinalEncoder(categories=[['low', 'high']]), ['Average_speed']),\n",
    "    ('t3', OneHotEncoder(sparse_output=False, drop='first'), ['Gender', 'City'])\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05030b77-2765-4357-808b-53a719a21661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 8), (20, 8))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit_transform(X_train).shape, transformer.transform(X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f1db3-a310-4c90-8d7e-cf80afe2305b",
   "metadata": {},
   "source": [
    "- Purpose of the remainder parameter specifies what to do with the columns not explicitly transformed by the transformers list.\n",
    "\n",
    "remainder='passthrough': It  Leaves all other columns untouched and includes them in the transformed output.\n",
    "\n",
    "- Why are we using this. As it is useful when you want to apply specific transformations to only some columns while preserving the rest as they are, ensuring that no information is lost from the original dataset.\n",
    "- This is about Column Transformer where each column values have been stored into single column transformer.\n",
    "As in Categorical Features we can't give machine the complete word. we transform it's data into matrix which is represtation of numbers then we give to machine for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69d4b7f7-70d0-49a2-b821-cb2e123019fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 8), (20, 8))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(X_train)\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n",
    "X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3154aa4-addc-4523-aaa6-66d6c9a7e6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Age  Gender  Speed Average_speed      City\n",
       " 82   51  female  170.0          high    Mumbai\n",
       " 14   37  female   70.0           low  Banglore\n",
       " 77   36    male  130.0          high  Banglore\n",
       " 25   35    male  100.0          high  Banglore\n",
       " 33   35  female   50.0           low  Banglore\n",
       " ..  ...     ...    ...           ...       ...\n",
       " 45   24  female   60.0           low   Kolkata\n",
       " 46   19  female   70.0           low  Banglore\n",
       " 26   47  female  130.0          high  Banglore\n",
       " 28   27  female  150.0          high     Delhi\n",
       " 84   46  female   50.0           low     Delhi\n",
       " \n",
       " [80 rows x 5 columns],\n",
       " (80, 5))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb4cb0e3-da00-4f0d-9c6f-25d706c7c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Age  Gender  Speed Average_speed      City\n",
       " 21   28  female   70.0           low  Banglore\n",
       " 86   34    male   60.0           low  Banglore\n",
       " 52   29    male   60.0           low    Mumbai\n",
       " 18   28    male   50.0           low  Banglore\n",
       " 39   26    male  150.0          high  Banglore\n",
       " 9    25    male   60.0           low     Delhi\n",
       " 83   39  female   70.0           low     Delhi\n",
       " 44   57    male   40.0           low     Delhi\n",
       " 64   28  female  180.0          high    Mumbai\n",
       " 53   42    male   80.0           low   Kolkata\n",
       " 36   36    male   50.0           low   Kolkata\n",
       " 10   35  female   80.0           low     Delhi\n",
       " 58   52    male  120.0          high  Banglore\n",
       " 65   37  female  170.0          high   Kolkata\n",
       " 8    42    male   70.0           low  Banglore\n",
       " 99   20    male   60.0           low   Kolkata\n",
       " 68   56    male    NaN           low     Delhi\n",
       " 97   40  female   50.0           low    Mumbai\n",
       " 90   24    male  120.0          high  Banglore\n",
       " 49   48  female  130.0          high  Banglore,\n",
       " (20, 5))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa9fb6-3a3b-4fa1-85c7-00ba8f63d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
